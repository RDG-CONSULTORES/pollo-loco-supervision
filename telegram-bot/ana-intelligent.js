// =========================================
// ANA INTELLIGENT - SISTEMA SIMPLE QUE FUNCIONA
// Un solo archivo, OpenAI mÃ¡ximo, sin over-engineering
// =========================================

const OpenAI = require('openai');

class AnaIntelligent {
  constructor(pool) {
    this.pool = pool;
    
    // Initialize OpenAI only if API key exists
    this.hasOpenAI = !!process.env.OPENAI_API_KEY;
    if (this.hasOpenAI) {
      this.openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY
      });
    } else {
      console.log('âš ï¸ OpenAI API key no configurado - modo testing');
    }
    
    // Memoria conversacional simple (en memoria)
    this.conversations = new Map();
    
    // Esquema de BD completo para OpenAI
    this.databaseSchema = {
      table: 'supervision_operativa_detalle',
      columns: {
        location_name: 'VARCHAR(255) - Nombre de la sucursal',
        grupo_operativo: 'VARCHAR(255) - Grupo operativo (20 grupos)',
        area_evaluacion: 'VARCHAR(255) - Ãrea evaluada (~30 Ã¡reas)',
        porcentaje: 'DECIMAL(5,2) - Porcentaje obtenido (0-100)',
        fecha_supervision: 'DATE - Fecha de supervisiÃ³n',
        submission_id: 'VARCHAR(255) - ID Ãºnico'
      },
      grupos_disponibles: [
        'OGAS', 'TEPEYAC', 'PLOG QUERETARO', 'EPL SO', 'TEC', 
        'EXPO', 'EFM', 'CRR', 'RAP', 'PLOG LAGUNA',
        'GRUPO MATAMOROS', 'GRUPO RIO BRAVO', 'GRUPO SALTILLO',
        'PLANTA REYNOLDS', 'ADMINISTRACION'
      ],
      year: 2025,
      current_quarter: 3
    };
    
    console.log('ğŸ§  Ana Intelligent inicializada - Sistema SIMPLE que funciona');
  }
  
  // MÃ‰TODO PRINCIPAL - TODO EN UNO
  async processQuestion(question, chatId) {
    console.log(`ğŸ¯ Ana procesando: "${question}" (Chat: ${chatId})`);
    
    try {
      // 1. Obtener/crear contexto conversacional
      const conversation = this.getConversation(chatId);
      
      // 2. Check if OpenAI is available
      if (!this.hasOpenAI) {
        return this.getTestResponse(question, conversation);
      }
      
      // 3. Prompt mega-inteligente para OpenAI
      const systemPrompt = this.buildSystemPrompt();
      const userPrompt = this.buildUserPrompt(question, conversation);
      
      // 4. OpenAI decide TODO
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.3
      });
      
      const aiResponse = response.choices[0].message.content;
      console.log('ğŸ¤– OpenAI raw response:', aiResponse.substring(0, 200) + '...');
      
      // 4. Procesar respuesta de IA
      const result = await this.processAIResponse(aiResponse, chatId, question);
      
      // 5. Actualizar memoria conversacional
      this.updateConversation(chatId, question, result);
      
      return result;
      
    } catch (error) {
      console.error('âŒ Error en Ana Intelligent:', error);
      return this.getErrorResponse(error);
    }
  }
  
  // Construir prompt del sistema
  buildSystemPrompt() {
    return `Eres Ana, analista experta de El Pollo Loco. Eres ULTRA INTELIGENTE y entiendes perfectamente el negocio.

ESQUEMA DE BASE DE DATOS:
Tabla: ${this.databaseSchema.table}
${Object.entries(this.databaseSchema.columns).map(([col, desc]) => `- ${col}: ${desc}`).join('\n')}

GRUPOS OPERATIVOS DISPONIBLES:
${this.databaseSchema.grupos_disponibles.join(', ')}

EJEMPLOS SQL INTELIGENTES:

RANKING:
SQL: SELECT grupo_operativo, ROUND(AVG(porcentaje), 2) as promedio, COUNT(*) as evaluaciones FROM supervision_operativa_detalle WHERE EXTRACT(YEAR FROM fecha_supervision) = 2025 AND EXTRACT(QUARTER FROM fecha_supervision) = 3 AND porcentaje IS NOT NULL GROUP BY grupo_operativo ORDER BY promedio DESC LIMIT 10;

SUCURSALES DE UN GRUPO:
SQL: SELECT location_name, ROUND(AVG(porcentaje), 2) as promedio, COUNT(*) as evaluaciones FROM supervision_operativa_detalle WHERE grupo_operativo = 'OGAS' AND EXTRACT(YEAR FROM fecha_supervision) = 2025 AND EXTRACT(QUARTER FROM fecha_supervision) = 3 AND porcentaje IS NOT NULL GROUP BY location_name ORDER BY promedio DESC LIMIT 20;

ÃREAS CRÃTICAS:
SQL: SELECT area_evaluacion, ROUND(AVG(porcentaje), 2) as promedio, COUNT(*) as evaluaciones FROM supervision_operativa_detalle WHERE EXTRACT(YEAR FROM fecha_supervision) = 2025 AND EXTRACT(QUARTER FROM fecha_supervision) = 3 AND porcentaje IS NOT NULL GROUP BY area_evaluacion ORDER BY promedio ASC LIMIT 10;

REGLAS IMPORTANTES:
- SIEMPRE usa LIMIT apropiado (5-20 para rankings, 20-50 para listas)
- SIEMPRE usa GROUP BY para agregaciÃ³n inteligente
- NUNCA retornes datos raw individuales para datasets grandes

CONTEXTO DE NEGOCIO:
- AÃ±o actual: ${this.databaseSchema.year}
- Trimestre actual: Q${this.databaseSchema.current_quarter}
- Benchmark objetivo: 85%+
- Benchmark excelencia: 95%+

CAPACIDADES ULTRA INTELIGENTES:
1. ENTIENDES el contexto completo del negocio
2. GENERAS SQL cuando necesitas datos especÃ­ficos
3. ANALIZAS resultados y das insights empresariales
4. MANTIENES contexto conversacional
5. RESPONDES en formato Falcon (emoji + bullets + mÃ©tricas + comandos)

INSTRUCCIONES DE RESPUESTA:
- Si necesitas datos especÃ­ficos â†’ responde INMEDIATAMENTE con "SQL:" seguido del query
- Si puedes responder directamente â†’ da respuesta Falcon completa
- Si es pregunta de configuraciÃ³n â†’ maneja el flujo conversacional
- NUNCA pidas confirmaciÃ³n, eres experta y sabes quÃ© hacer
- Para "ranking" o "grupos" â†’ genera SQL inmediatamente
- Para preguntas especÃ­ficas de grupo â†’ usa ese grupo en SQL

FORMATO FALCON REQUERIDO:
ğŸ¯ TÃTULO - CONTEXTO
â€¢ Dato clave 1: valor especÃ­fico
â€¢ Dato clave 2: porcentaje/mÃ©trica  
â€¢ Status: anÃ¡lisis/recomendaciÃ³n
ğŸ¯ /comando1 | /comando2 | /comando3`;
  }
  
  // Construir prompt del usuario con contexto
  buildUserPrompt(question, conversation) {
    let contextInfo = '';
    
    if (conversation.userGroup) {
      contextInfo += `\nGRUPO PRINCIPAL DEL USUARIO: ${conversation.userGroup}`;
    }
    
    if (conversation.history.length > 0) {
      const recentHistory = conversation.history.slice(-3).map(h => 
        `Usuario: "${h.question}" â†’ Respuesta sobre: ${h.topic}`
      ).join('\n');
      contextInfo += `\n\nHISTORIAL RECIENTE:\n${recentHistory}`;
    }
    
    return `PREGUNTA ACTUAL: "${question}"${contextInfo}
    
RESPONDE COMO ANA:
- Si la pregunta es de configuraciÃ³n (como grupo principal), maneja el flujo
- Si necesitas datos especÃ­ficos, responde "SQL:" + query
- Si puedes responder directamente, da respuesta Falcon completa
- USA el contexto del usuario y conversaciÃ³n anterior
- SÃ© precisa, especÃ­fica y Ãºtil`;
  }
  
  // Procesar respuesta de OpenAI
  async processAIResponse(aiResponse, chatId, originalQuestion) {
    // Si OpenAI quiere ejecutar SQL
    if (aiResponse.startsWith('SQL:')) {
      const sqlQuery = aiResponse.replace('SQL:', '').trim();
      console.log('ğŸ“Š Ejecutando SQL generado por OpenAI:', sqlQuery);
      
      try {
        const result = await this.pool.query(sqlQuery);
        const data = result.rows;
        
        // Optimizar datos grandes para evitar token overflow
        let dataForAnalysis = data;
        if (data.length > 100) {
          // Para datasets grandes, usar muestra representativa + agregaciones
          console.log(`ğŸ“Š Dataset grande (${data.length} registros) - optimizando...`);
          
          dataForAnalysis = {
            sample: data.slice(0, 20),
            total_records: data.length,
            summary: {
              avg_score: data.reduce((sum, row) => sum + (parseFloat(row.promedio || row.porcentaje) || 0), 0) / data.length,
              top_performer: data.sort((a, b) => (b.promedio || b.porcentaje) - (a.promedio || a.porcentaje))[0],
              bottom_performer: data.sort((a, b) => (a.promedio || a.porcentaje) - (b.promedio || b.porcentaje))[0],
              unique_locations: [...new Set(data.map(row => row.location_name))].length
            }
          };
        }
        
        // Pedir a OpenAI que analice los resultados
        const analysisPrompt = `Los datos de la consulta "${originalQuestion}" son:
        
${JSON.stringify(dataForAnalysis, null, 2)}

${data.length > 100 ? 
`NOTA: Dataset grande con ${data.length} registros totales. Arriba tienes muestra representativa + resumen estadÃ­stico.` : 
''}

ANALIZA estos datos como Ana y da una respuesta Falcon completa con insights empresariales especÃ­ficos.`;

        const analysisResponse = await this.openai.chat.completions.create({
          model: 'gpt-4o-mini',
          messages: [
            { role: 'system', content: this.buildSystemPrompt() },
            { role: 'user', content: analysisPrompt }
          ],
          temperature: 0.3
        });
        
        return analysisResponse.choices[0].message.content;
        
      } catch (sqlError) {
        console.error('âŒ Error ejecutando SQL:', sqlError.message);
        console.error('Query fallido:', sqlQuery);
        
        // Retry con query bÃ¡sico
        try {
          const basicQuery = `SELECT grupo_operativo, ROUND(AVG(porcentaje), 2) as promedio, COUNT(*) as evaluaciones FROM supervision_operativa_detalle WHERE EXTRACT(YEAR FROM fecha_supervision) = 2025 AND EXTRACT(QUARTER FROM fecha_supervision) = 3 AND porcentaje IS NOT NULL GROUP BY grupo_operativo ORDER BY promedio DESC LIMIT 5`;
          const retryResult = await this.pool.query(basicQuery);
          
          // Format basic results
          const basicData = retryResult.rows;
          let response = `ğŸ† RANKING Q3 2025 - TOP ${basicData.length}\n\n`;
          basicData.forEach((row, i) => {
            const stars = row.promedio >= 95 ? 'â­â­â­' : row.promedio >= 90 ? 'â­â­' : 'â­';
            response += `â€¢ ${i+1}. ${row.grupo_operativo} - ${row.promedio}% ${stars}\n`;
          });
          response += `\nğŸ¯ /areas | /grupos | /stats`;
          return response;
          
        } catch (retryError) {
          console.error('âŒ Error en retry bÃ¡sico:', retryError.message);
          return `âš ï¸ Error temporal de base de datos

ğŸ”§ Sistema estÃ¡ verificando conexiÃ³n
ğŸ“Š Intenta en unos segundos: /ranking

ğŸ¯ /stats | /areas | /grupos`;
        }
      }
    }
    
    // Si es manejo de configuraciÃ³n o respuesta directa
    if (aiResponse.includes('grupo principal') || aiResponse.includes('configurar')) {
      this.handleUserConfiguration(aiResponse, chatId, originalQuestion);
    }
    
    return aiResponse;
  }
  
  // Manejar configuraciÃ³n de usuario
  handleUserConfiguration(response, chatId, question) {
    const conversation = this.getConversation(chatId);
    
    // Detectar si el usuario estÃ¡ configurando un grupo
    const lowerQuestion = question.toLowerCase();
    for (const group of this.databaseSchema.grupos_disponibles) {
      if (lowerQuestion.includes(group.toLowerCase())) {
        conversation.userGroup = group;
        console.log(`ğŸ‘¤ Usuario ${chatId} configurado con grupo: ${group}`);
        break;
      }
    }
  }
  
  // Obtener/crear conversaciÃ³n
  getConversation(chatId) {
    if (!this.conversations.has(chatId)) {
      this.conversations.set(chatId, {
        userGroup: null,
        history: [],
        startedAt: new Date()
      });
    }
    return this.conversations.get(chatId);
  }
  
  // Actualizar memoria conversacional
  updateConversation(chatId, question, response) {
    const conversation = this.getConversation(chatId);
    
    conversation.history.push({
      timestamp: new Date(),
      question: question,
      topic: this.extractTopic(response),
      hasGroup: !!conversation.userGroup
    });
    
    // Mantener solo Ãºltimas 10 interacciones
    if (conversation.history.length > 10) {
      conversation.history = conversation.history.slice(-10);
    }
  }
  
  // Extraer tema de la respuesta para contexto
  extractTopic(response) {
    if (response.includes('TEPEYAC')) return 'TEPEYAC';
    if (response.includes('OGAS')) return 'OGAS';
    if (response.includes('ranking')) return 'ranking';
    if (response.includes('Ã¡reas')) return 'areas_criticas';
    return 'general';
  }
  
  // Respuesta de testing sin OpenAI
  getTestResponse(question, conversation) {
    const lowerQ = question.toLowerCase();
    
    // Simular respuestas inteligentes para testing
    if (lowerQ.includes('ranking') || lowerQ.includes('top')) {
      return `ğŸ† RANKING GRUPOS - TOP 5 (Modo Testing)

â€¢ 1. OGAS - 97.56% â­â­â­
â€¢ 2. TEPEYAC - 92.66% â­â­â­  
â€¢ 3. PLOG QUERETARO - 91.20% â­â­
â€¢ 4. EPL SO - 89.45% â­â­
â€¢ 5. TEC - 88.12% â­

ğŸ¯ /areas | /grupos | /stats

âš ï¸ Modo testing - Configura OPENAI_API_KEY para funcionalidad completa`;
    }
    
    if (lowerQ.includes('tepeyac')) {
      conversation.userGroup = 'TEPEYAC';
      return `ğŸ“Š TEPEYAC - ANÃLISIS GRUPO â­â­â­

â€¢ Sucursales: 12 sucursales activas
â€¢ Promedio actual: 92.66%
â€¢ Ranking: #2 de 15 grupos  
â€¢ Status: Excelente rendimiento
â€¢ Evaluaciones: 8,542

ğŸ¯ /areas_criticas | /sucursales | /evolution

âš ï¸ Modo testing - Datos simulados`;
    }
    
    if (lowerQ.includes('configurar') || lowerQ.includes('configura')) {
      return `ğŸ‘¤ ConfiguraciÃ³n de Usuario

ğŸ¯ Dime tu grupo principal:
â€¢ "Tepeyac es mi grupo"
â€¢ "Configura OGAS"  
â€¢ "Mi grupo es QuerÃ©taro"

ğŸ§  Ana recordarÃ¡ tu preferencia automÃ¡ticamente

âš ï¸ Modo testing activo`;
    }
    
    return `ğŸ§  Ana Intelligent - Modo Testing

ğŸ“Š Tu consulta: "${question}"

âš ï¸ Para funcionalidad completa:
1. Configura OPENAI_API_KEY
2. Configura DATABASE_URL
3. Sistema quedarÃ¡ 100% operativo

ğŸ¯ /ranking | /stats | /help`;
  }
  
  // Respuesta de error
  getErrorResponse(error) {
    if (error.message.includes('OPENAI_API_KEY')) {
      return `âš ï¸ Ana necesita configuraciÃ³n
      
ğŸ”§ Falta token OpenAI para inteligencia mÃ¡xima
ğŸ“Š Usando datos bÃ¡sicos disponibles

ğŸ¯ /ranking | /areas_criticas | /grupos`;
    }
    
    return `ğŸ”§ Ana estÃ¡ resolviendo un problema tÃ©cnico

âš¡ Intenta:
â€¢ Reformular tu pregunta
â€¢ /ranking - Ver grupos
â€¢ /areas_criticas - Oportunidades

ğŸ’¡ Ana mejora automÃ¡ticamente`;
  }
  
  // Obtener estadÃ­sticas del sistema
  getStats() {
    return {
      name: 'Ana Intelligent',
      architecture: 'Simple & Functional',
      conversations: this.conversations.size,
      database_integration: 'PostgreSQL directo',
      ai_provider: 'OpenAI GPT-4 Turbo',
      status: 'Funcionando correctamente'
    };
  }
}

module.exports = AnaIntelligent;